# Evaluating group fairness in online tutoring rankings

### Bachelor Thesis Universitat Pompeu Fabra
#### Javier Rando Ramírez
#### June 2021

---

Ensuring equal opportunities for everyone is one of the main concerns of modern societies. Machine learning algorithms emerged as a tool to make fair decisions since they should be free from human biases. However, many scandals have shown that this is not the case. In fact, artificial intelligence can reproduce discrimination against groups of people. Given the complexity of the systems and their opacity, it is really important to monitor their results and evaluate potential biases. In this work, we evaluate fairness in search engines retrieving people as results. We focus on online language tutoring platforms where teachers are hired to teach a language. First elements in the ranking will potentially obtain more students. Thus, if some groups are undervalued by the algorithm, they will be less likely to earn income from the platform. Furthermore, we measure how price varies depending on teachers background and attributes. The protected attributes monitored in the analysis are gender and country of origin.

---

⚠️ &nbsp; Released data is anonymized to avoid user identification. Also, output cells containing personal information have been deleted. If you want access to detailed experimental data, feel free to contact me. &nbsp; ⚠️

---

### Contents
This repository contains the whole code used throught my Bachelor Thesis. It is structured in three main sections:
* `data-acquisition/`: Contains the Python scripts used to crawl the information from websites. Notice that sources might be updated and the provided code might be no longer useful.
* `analysis/`: Jupyter Notebooks required to reproduce results.
* `data/`: Anonymized datasets.

Each of the folders contain a README file with further intructions on organization and execution.

Also a PDF version of my Bachelor Thesis can be found in the main folder of this repository.

---
